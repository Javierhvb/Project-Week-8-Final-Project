{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary libraries\n",
    "import requests\n",
    "from pytrends.request import TrendReq\n",
    "from pytrends import dailydata\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytrends = TrendReq(hl='en-US', tz=360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['netflix', 'nike', 'starbucks', 'yelp', 'tesla', 'amazon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which return the google trends per hour from a keyword, given the keyword and begin/end dates\n",
    "def get_hourly_interest(company, begin_year, begin_month_start, begin_day, end_year, end_month, end_day):\n",
    "    hourly = pytrends.get_historical_interest(company, year_start = begin_year, month_start=begin_month, day_start = begin_day, hour_start = 0, year_end = end_year, month_end=end_month, day_end=end_day, hour_end = 0, sleep = 5)\n",
    "    hourly.to_csv(f'../02 CSV_files/trends/{company}_trends_from{begin_day}{begin_month}{begin_year}_to{end_day}{end_month}{end_year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which returns the interest in a keyword on a weekly basis for the last 5 years. It saves it as the keyword weekly trends\n",
    "def download_and_save_interest(company_name):\n",
    "    pytrends.build_payload(company_name)\n",
    "    trends = pytrends.interest_over_time()\n",
    "    trends.to_csv(f'../02 CSV_files/trends/{company_name[0]}_weekly_trends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which reads a csv file, given the path\n",
    "def read_and_create_df(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which cleans the trends dataframe returned by the function get_hourly_interest or download_and_save_interest\n",
    "def cleaning_trends_dataframe(df):\n",
    "    df['hour'] = df['date'].apply(pd.to_datetime)\n",
    "    df['date'] = df['hour'].dt.date\n",
    "    df['week'] = df['hour'].dt.week\n",
    "    df['month'] = df['hour'].dt.month\n",
    "    df['year'] = df['hour'].dt.year\n",
    "    df.drop('isPartial', axis = 1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which adds 3 features to the trends dataframes (last weeks trends, % interest and the name of the company)\n",
    "def add_features_df(df):\n",
    "    df['last_week'] = df[df.columns[1]].shift()\n",
    "    df['perc_incr'] = (df[df.columns[1]] - df['last_week']) / df['last_week']\n",
    "    company_name = df.columns[1]\n",
    "    df['company'] = company_name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which returns the 20 weeks with higher increase percentage in the trends and \n",
    "#gets the hourly interest of the previous week and the mentioned week. Appending all the gathered date into one dataframe\n",
    "def hourly_peaks_interest(weekly_df):\n",
    "    total_peaks = pd.DataFrame()\n",
    "    for date in weekly_df.sort_values(by = 'perc_incr', ascending = False).head(20).date:\n",
    "        begin_date = date - dt.timedelta(days = 7)\n",
    "        end_date = date + dt.timedelta(days = 7)\n",
    "        hourly = pytrends.get_historical_interest([weekly_df.columns[1]], year_start = begin_date.year, month_start=begin_date.month, day_start = begin_date.day, hour_start = 0, year_end = end_date.year, month_end=end_date.month, day_end=end_date.day, hour_end = 0, sleep = 5)\n",
    "        company_name = weekly_df.columns[1]\n",
    "        weekly_df['company'] = company_name\n",
    "        total_peaks = total_peaks.append(hourly)\n",
    "    return total_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_hourly_trends_dataframes(companys_list):\n",
    "    final_df = pd.DataFrame()\n",
    "    for company in companies:\n",
    "        download_and_save_interest([company])\n",
    "        company_df = read_and_create_df(f'../02 CSV_files/trends/{company}_weekly_trends.csv')\n",
    "        cleaned_df = cleaning_trends_dataframe(company_df)\n",
    "        complete_df = add_features_df(cleaned_df)\n",
    "        peaks_df = hourly_peaks_interest(complete_df)\n",
    "        final_df = final_df.append(peaks_df)\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_trends_dataframe(company):\n",
    "    download_and_save_interest(company)\n",
    "    company_df = read_and_create_df(f'../02 CSV_files/trends/{company}_weekly_trends.csv')\n",
    "    cleaned_df = cleaning_trends_dataframe(company_df)\n",
    "    complete_df = add_features_df(cleaned_df)\n",
    "    peaks_df = hourly_peaks_interest(complete_df)\n",
    "    final_df = final_df.append(peaks_df)\n",
    "    return final_df\n",
    "\n",
    "#final_df = all_hourly_trends_dataframes(companies)\n",
    "#final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../02 CSV_files/hourly_peaks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which collects the daily google trends of a keyword from the specified timerange\n",
    "def get_daily_trends(company, year_begin, month_begin, year_end, month_end):\n",
    "    df = dailydata.get_daily_data(company, year_begin, month_begin, year_end, month_end)\n",
    "    df.drop(columns = ['isPartial',f'{company}_monthly', 'scale'], inplace = True)\n",
    "    df = df.reset_index()\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df.rename(columns = {f'{company}_unscaled':'unscaled', f'{company}':'scaled'}, inplace = True)\n",
    "    df['name'] = company\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which iterates through a list of keywords and saves it in the trends file\n",
    "def companies_daily_trends(companies_list, begin_year,begin_month, end_year, end_month):\n",
    "    daily_trends = pd.DataFrame(columns = ['date', 'unscaled','scaled'])\n",
    "    for company in companies_list:\n",
    "        for year in range(begin_year,end_year+1):\n",
    "            new_df = get_daily_trends(company,year,begin_month,year,end_month)\n",
    "            daily_trends = daily_trends.append(new_df)\n",
    "            daily_trends.to_csv(f'../02 CSV_files/trends/daily_trends_{company}{year}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which iterates through a list of keywords and saves it in the trends file\n",
    "def companies_daily_trends_2(companies_list, begin_year,begin_month, end_year, end_month):\n",
    "    daily_trends = pd.DataFrame(columns = ['date', 'unscaled','scaled'])\n",
    "    for company in companies_list:\n",
    "        new_df = get_daily_trends(company,begin_year,begin_month,end_year,end_month)\n",
    "        daily_trends = daily_trends.append(new_df)\n",
    "        daily_trends.to_csv(f'../02 CSV_files/trends/daily_trends_{company}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netflix:2015-01-01 2015-01-31\n",
      "netflix:2015-02-01 2015-02-28\n",
      "netflix:2015-03-01 2015-03-31\n",
      "netflix:2015-04-01 2015-04-30\n",
      "netflix:2015-05-01 2015-05-31\n",
      "netflix:2015-06-01 2015-06-30\n",
      "netflix:2015-07-01 2015-07-31\n",
      "netflix:2015-08-01 2015-08-31\n",
      "netflix:2015-09-01 2015-09-30\n",
      "netflix:2015-10-01 2015-10-31\n",
      "netflix:2015-11-01 2015-11-30\n",
      "netflix:2015-12-01 2015-12-31\n",
      "netflix:2016-01-01 2016-01-31\n",
      "netflix:2016-02-01 2016-02-29\n",
      "netflix:2016-03-01 2016-03-31\n",
      "netflix:2016-04-01 2016-04-30\n",
      "netflix:2016-05-01 2016-05-31\n",
      "netflix:2016-06-01 2016-06-30\n",
      "netflix:2016-07-01 2016-07-31\n",
      "netflix:2016-08-01 2016-08-31\n",
      "netflix:2016-09-01 2016-09-30\n",
      "netflix:2016-10-01 2016-10-31\n",
      "netflix:2016-11-01 2016-11-30\n",
      "netflix:2016-12-01 2016-12-31\n",
      "netflix:2017-01-01 2017-01-31\n",
      "netflix:2017-02-01 2017-02-28\n",
      "netflix:2017-03-01 2017-03-31\n",
      "netflix:2017-04-01 2017-04-30\n",
      "netflix:2017-05-01 2017-05-31\n",
      "netflix:2017-06-01 2017-06-30\n",
      "netflix:2017-07-01 2017-07-31\n",
      "netflix:2017-08-01 2017-08-31\n",
      "netflix:2017-09-01 2017-09-30\n",
      "netflix:2017-10-01 2017-10-31\n",
      "netflix:2017-11-01 2017-11-30\n",
      "netflix:2017-12-01 2017-12-31\n",
      "netflix:2018-01-01 2018-01-31\n",
      "netflix:2018-02-01 2018-02-28\n",
      "netflix:2018-03-01 2018-03-31\n",
      "netflix:2018-04-01 2018-04-30\n",
      "netflix:2018-05-01 2018-05-31\n",
      "netflix:2018-06-01 2018-06-30\n",
      "netflix:2018-07-01 2018-07-31\n",
      "netflix:2018-08-01 2018-08-31\n",
      "netflix:2018-09-01 2018-09-30\n",
      "netflix:2018-10-01 2018-10-31\n",
      "netflix:2018-11-01 2018-11-30\n",
      "netflix:2018-12-01 2018-12-31\n",
      "netflix:2019-01-01 2019-01-31\n",
      "netflix:2019-02-01 2019-02-28\n",
      "netflix:2019-03-01 2019-03-31\n",
      "netflix:2019-04-01 2019-04-30\n",
      "netflix:2019-05-01 2019-05-31\n",
      "netflix:2019-06-01 2019-06-30\n",
      "netflix:2019-07-01 2019-07-31\n",
      "netflix:2019-08-01 2019-08-31\n",
      "netflix:2019-09-01 2019-09-30\n",
      "netflix:2019-10-01 2019-10-31\n",
      "netflix:2019-11-01 2019-11-30\n",
      "netflix:2019-12-01 2019-12-31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nike:2015-01-01 2015-01-31\n",
      "nike:2015-02-01 2015-02-28\n",
      "nike:2015-03-01 2015-03-31\n",
      "nike:2015-04-01 2015-04-30\n",
      "nike:2015-05-01 2015-05-31\n",
      "nike:2015-06-01 2015-06-30\n",
      "nike:2015-07-01 2015-07-31\n",
      "nike:2015-08-01 2015-08-31\n",
      "nike:2015-09-01 2015-09-30\n",
      "nike:2015-10-01 2015-10-31\n",
      "nike:2015-11-01 2015-11-30\n",
      "nike:2015-12-01 2015-12-31\n",
      "nike:2016-01-01 2016-01-31\n",
      "nike:2016-02-01 2016-02-29\n",
      "nike:2016-03-01 2016-03-31\n",
      "nike:2016-04-01 2016-04-30\n",
      "nike:2016-05-01 2016-05-31\n",
      "nike:2016-06-01 2016-06-30\n",
      "nike:2016-07-01 2016-07-31\n",
      "nike:2016-08-01 2016-08-31\n",
      "nike:2016-09-01 2016-09-30\n",
      "nike:2016-10-01 2016-10-31\n",
      "nike:2016-11-01 2016-11-30\n",
      "nike:2016-12-01 2016-12-31\n",
      "nike:2017-01-01 2017-01-31\n",
      "nike:2017-02-01 2017-02-28\n",
      "nike:2017-03-01 2017-03-31\n",
      "nike:2017-04-01 2017-04-30\n",
      "nike:2017-05-01 2017-05-31\n",
      "nike:2017-06-01 2017-06-30\n",
      "nike:2017-07-01 2017-07-31\n",
      "nike:2017-08-01 2017-08-31\n",
      "nike:2017-09-01 2017-09-30\n",
      "nike:2017-10-01 2017-10-31\n",
      "nike:2017-11-01 2017-11-30\n",
      "nike:2017-12-01 2017-12-31\n",
      "nike:2018-01-01 2018-01-31\n",
      "nike:2018-02-01 2018-02-28\n",
      "nike:2018-03-01 2018-03-31\n",
      "nike:2018-04-01 2018-04-30\n",
      "nike:2018-05-01 2018-05-31\n",
      "nike:2018-06-01 2018-06-30\n",
      "nike:2018-07-01 2018-07-31\n",
      "nike:2018-08-01 2018-08-31\n",
      "nike:2018-09-01 2018-09-30\n",
      "nike:2018-10-01 2018-10-31\n",
      "nike:2018-11-01 2018-11-30\n",
      "nike:2018-12-01 2018-12-31\n",
      "nike:2019-01-01 2019-01-31\n",
      "nike:2019-02-01 2019-02-28\n",
      "nike:2019-03-01 2019-03-31\n",
      "nike:2019-04-01 2019-04-30\n",
      "nike:2019-05-01 2019-05-31\n",
      "nike:2019-06-01 2019-06-30\n",
      "nike:2019-07-01 2019-07-31\n",
      "nike:2019-08-01 2019-08-31\n",
      "nike:2019-09-01 2019-09-30\n",
      "nike:2019-10-01 2019-10-31\n",
      "nike:2019-11-01 2019-11-30\n",
      "nike:2019-12-01 2019-12-31\n",
      "starbucks:2015-01-01 2015-01-31\n",
      "starbucks:2015-02-01 2015-02-28\n",
      "starbucks:2015-03-01 2015-03-31\n",
      "starbucks:2015-04-01 2015-04-30\n",
      "starbucks:2015-05-01 2015-05-31\n",
      "starbucks:2015-06-01 2015-06-30\n",
      "starbucks:2015-07-01 2015-07-31\n",
      "starbucks:2015-08-01 2015-08-31\n",
      "starbucks:2015-09-01 2015-09-30\n",
      "starbucks:2015-10-01 2015-10-31\n",
      "starbucks:2015-11-01 2015-11-30\n",
      "starbucks:2015-12-01 2015-12-31\n",
      "starbucks:2016-01-01 2016-01-31\n",
      "starbucks:2016-02-01 2016-02-29\n",
      "starbucks:2016-03-01 2016-03-31\n",
      "starbucks:2016-04-01 2016-04-30\n",
      "starbucks:2016-05-01 2016-05-31\n",
      "starbucks:2016-06-01 2016-06-30\n",
      "starbucks:2016-07-01 2016-07-31\n",
      "starbucks:2016-08-01 2016-08-31\n",
      "starbucks:2016-09-01 2016-09-30\n",
      "starbucks:2016-10-01 2016-10-31\n",
      "starbucks:2016-11-01 2016-11-30\n",
      "starbucks:2016-12-01 2016-12-31\n",
      "starbucks:2017-01-01 2017-01-31\n",
      "starbucks:2017-02-01 2017-02-28\n",
      "starbucks:2017-03-01 2017-03-31\n",
      "starbucks:2017-04-01 2017-04-30\n",
      "starbucks:2017-05-01 2017-05-31\n",
      "starbucks:2017-06-01 2017-06-30\n",
      "starbucks:2017-07-01 2017-07-31\n",
      "starbucks:2017-08-01 2017-08-31\n",
      "starbucks:2017-09-01 2017-09-30\n",
      "starbucks:2017-10-01 2017-10-31\n",
      "starbucks:2017-11-01 2017-11-30\n",
      "starbucks:2017-12-01 2017-12-31\n",
      "starbucks:2018-01-01 2018-01-31\n",
      "starbucks:2018-02-01 2018-02-28\n",
      "starbucks:2018-03-01 2018-03-31\n",
      "starbucks:2018-04-01 2018-04-30\n",
      "starbucks:2018-05-01 2018-05-31\n",
      "starbucks:2018-06-01 2018-06-30\n",
      "starbucks:2018-07-01 2018-07-31\n",
      "starbucks:2018-08-01 2018-08-31\n",
      "starbucks:2018-09-01 2018-09-30\n",
      "starbucks:2018-10-01 2018-10-31\n",
      "starbucks:2018-11-01 2018-11-30\n",
      "starbucks:2018-12-01 2018-12-31\n",
      "starbucks:2019-01-01 2019-01-31\n",
      "starbucks:2019-02-01 2019-02-28\n",
      "starbucks:2019-03-01 2019-03-31\n",
      "starbucks:2019-04-01 2019-04-30\n",
      "starbucks:2019-05-01 2019-05-31\n",
      "starbucks:2019-06-01 2019-06-30\n",
      "starbucks:2019-07-01 2019-07-31\n",
      "starbucks:2019-08-01 2019-08-31\n",
      "starbucks:2019-09-01 2019-09-30\n",
      "starbucks:2019-10-01 2019-10-31\n",
      "starbucks:2019-11-01 2019-11-30\n",
      "starbucks:2019-12-01 2019-12-31\n",
      "yelp:2015-01-01 2015-01-31\n",
      "yelp:2015-02-01 2015-02-28\n",
      "yelp:2015-03-01 2015-03-31\n",
      "yelp:2015-04-01 2015-04-30\n",
      "yelp:2015-05-01 2015-05-31\n",
      "yelp:2015-06-01 2015-06-30\n",
      "yelp:2015-07-01 2015-07-31\n",
      "yelp:2015-08-01 2015-08-31\n",
      "yelp:2015-09-01 2015-09-30\n",
      "yelp:2015-10-01 2015-10-31\n",
      "yelp:2015-11-01 2015-11-30\n",
      "yelp:2015-12-01 2015-12-31\n",
      "yelp:2016-01-01 2016-01-31\n",
      "yelp:2016-02-01 2016-02-29\n",
      "yelp:2016-03-01 2016-03-31\n",
      "yelp:2016-04-01 2016-04-30\n",
      "yelp:2016-05-01 2016-05-31\n",
      "yelp:2016-06-01 2016-06-30\n",
      "yelp:2016-07-01 2016-07-31\n",
      "yelp:2016-08-01 2016-08-31\n",
      "yelp:2016-09-01 2016-09-30\n",
      "yelp:2016-10-01 2016-10-31\n",
      "yelp:2016-11-01 2016-11-30\n",
      "yelp:2016-12-01 2016-12-31\n",
      "yelp:2017-01-01 2017-01-31\n",
      "yelp:2017-02-01 2017-02-28\n",
      "yelp:2017-03-01 2017-03-31\n",
      "yelp:2017-04-01 2017-04-30\n",
      "yelp:2017-05-01 2017-05-31\n",
      "yelp:2017-06-01 2017-06-30\n",
      "yelp:2017-07-01 2017-07-31\n",
      "yelp:2017-08-01 2017-08-31\n",
      "yelp:2017-09-01 2017-09-30\n",
      "yelp:2017-10-01 2017-10-31\n",
      "yelp:2017-11-01 2017-11-30\n",
      "yelp:2017-12-01 2017-12-31\n",
      "yelp:2018-01-01 2018-01-31\n",
      "yelp:2018-02-01 2018-02-28\n",
      "yelp:2018-03-01 2018-03-31\n",
      "yelp:2018-04-01 2018-04-30\n",
      "yelp:2018-05-01 2018-05-31\n",
      "yelp:2018-06-01 2018-06-30\n",
      "yelp:2018-07-01 2018-07-31\n",
      "yelp:2018-08-01 2018-08-31\n",
      "yelp:2018-09-01 2018-09-30\n",
      "yelp:2018-10-01 2018-10-31\n",
      "yelp:2018-11-01 2018-11-30\n",
      "yelp:2018-12-01 2018-12-31\n",
      "yelp:2019-01-01 2019-01-31\n",
      "yelp:2019-02-01 2019-02-28\n",
      "yelp:2019-03-01 2019-03-31\n",
      "yelp:2019-04-01 2019-04-30\n",
      "yelp:2019-05-01 2019-05-31\n",
      "yelp:2019-06-01 2019-06-30\n",
      "yelp:2019-07-01 2019-07-31\n",
      "yelp:2019-08-01 2019-08-31\n",
      "yelp:2019-09-01 2019-09-30\n",
      "yelp:2019-10-01 2019-10-31\n",
      "yelp:2019-11-01 2019-11-30\n",
      "yelp:2019-12-01 2019-12-31\n",
      "tesla:2015-01-01 2015-01-31\n",
      "tesla:2015-02-01 2015-02-28\n",
      "tesla:2015-03-01 2015-03-31\n",
      "tesla:2015-04-01 2015-04-30\n",
      "tesla:2015-05-01 2015-05-31\n",
      "tesla:2015-06-01 2015-06-30\n",
      "tesla:2015-07-01 2015-07-31\n",
      "tesla:2015-08-01 2015-08-31\n",
      "tesla:2015-09-01 2015-09-30\n",
      "tesla:2015-10-01 2015-10-31\n",
      "tesla:2015-11-01 2015-11-30\n",
      "tesla:2015-12-01 2015-12-31\n",
      "tesla:2016-01-01 2016-01-31\n",
      "tesla:2016-02-01 2016-02-29\n",
      "tesla:2016-03-01 2016-03-31\n",
      "tesla:2016-04-01 2016-04-30\n",
      "tesla:2016-05-01 2016-05-31\n",
      "tesla:2016-06-01 2016-06-30\n",
      "tesla:2016-07-01 2016-07-31\n",
      "tesla:2016-08-01 2016-08-31\n",
      "tesla:2016-09-01 2016-09-30\n",
      "tesla:2016-10-01 2016-10-31\n",
      "tesla:2016-11-01 2016-11-30\n",
      "tesla:2016-12-01 2016-12-31\n",
      "tesla:2017-01-01 2017-01-31\n",
      "tesla:2017-02-01 2017-02-28\n",
      "tesla:2017-03-01 2017-03-31\n",
      "tesla:2017-04-01 2017-04-30\n",
      "tesla:2017-05-01 2017-05-31\n",
      "tesla:2017-06-01 2017-06-30\n",
      "tesla:2017-07-01 2017-07-31\n",
      "tesla:2017-08-01 2017-08-31\n",
      "tesla:2017-09-01 2017-09-30\n",
      "tesla:2017-10-01 2017-10-31\n",
      "tesla:2017-11-01 2017-11-30\n",
      "tesla:2017-12-01 2017-12-31\n",
      "tesla:2018-01-01 2018-01-31\n",
      "tesla:2018-02-01 2018-02-28\n",
      "tesla:2018-03-01 2018-03-31\n",
      "tesla:2018-04-01 2018-04-30\n",
      "tesla:2018-05-01 2018-05-31\n",
      "tesla:2018-06-01 2018-06-30\n",
      "tesla:2018-07-01 2018-07-31\n",
      "tesla:2018-08-01 2018-08-31\n",
      "tesla:2018-09-01 2018-09-30\n",
      "tesla:2018-10-01 2018-10-31\n",
      "tesla:2018-11-01 2018-11-30\n",
      "tesla:2018-12-01 2018-12-31\n",
      "tesla:2019-01-01 2019-01-31\n",
      "tesla:2019-02-01 2019-02-28\n",
      "tesla:2019-03-01 2019-03-31\n",
      "tesla:2019-04-01 2019-04-30\n",
      "tesla:2019-05-01 2019-05-31\n",
      "tesla:2019-06-01 2019-06-30\n",
      "tesla:2019-07-01 2019-07-31\n",
      "tesla:2019-08-01 2019-08-31\n",
      "tesla:2019-09-01 2019-09-30\n",
      "tesla:2019-10-01 2019-10-31\n",
      "tesla:2019-11-01 2019-11-30\n",
      "tesla:2019-12-01 2019-12-31\n",
      "amazon:2015-01-01 2015-01-31\n",
      "amazon:2015-02-01 2015-02-28\n",
      "amazon:2015-03-01 2015-03-31\n",
      "amazon:2015-04-01 2015-04-30\n",
      "amazon:2015-05-01 2015-05-31\n",
      "amazon:2015-06-01 2015-06-30\n",
      "amazon:2015-07-01 2015-07-31\n",
      "amazon:2015-08-01 2015-08-31\n",
      "amazon:2015-09-01 2015-09-30\n",
      "amazon:2015-10-01 2015-10-31\n",
      "amazon:2015-11-01 2015-11-30\n",
      "amazon:2015-12-01 2015-12-31\n",
      "amazon:2016-01-01 2016-01-31\n",
      "amazon:2016-02-01 2016-02-29\n",
      "amazon:2016-03-01 2016-03-31\n",
      "amazon:2016-04-01 2016-04-30\n",
      "amazon:2016-05-01 2016-05-31\n",
      "amazon:2016-06-01 2016-06-30\n",
      "amazon:2016-07-01 2016-07-31\n",
      "amazon:2016-08-01 2016-08-31\n",
      "amazon:2016-09-01 2016-09-30\n",
      "amazon:2016-10-01 2016-10-31\n",
      "amazon:2016-11-01 2016-11-30\n",
      "amazon:2016-12-01 2016-12-31\n",
      "amazon:2017-01-01 2017-01-31\n",
      "amazon:2017-02-01 2017-02-28\n",
      "amazon:2017-03-01 2017-03-31\n",
      "amazon:2017-04-01 2017-04-30\n",
      "amazon:2017-05-01 2017-05-31\n",
      "amazon:2017-06-01 2017-06-30\n",
      "amazon:2017-07-01 2017-07-31\n",
      "amazon:2017-08-01 2017-08-31\n",
      "amazon:2017-09-01 2017-09-30\n",
      "amazon:2017-10-01 2017-10-31\n",
      "amazon:2017-11-01 2017-11-30\n",
      "amazon:2017-12-01 2017-12-31\n",
      "amazon:2018-01-01 2018-01-31\n",
      "amazon:2018-02-01 2018-02-28\n",
      "amazon:2018-03-01 2018-03-31\n",
      "amazon:2018-04-01 2018-04-30\n",
      "amazon:2018-05-01 2018-05-31\n",
      "amazon:2018-06-01 2018-06-30\n",
      "amazon:2018-07-01 2018-07-31\n",
      "amazon:2018-08-01 2018-08-31\n",
      "amazon:2018-09-01 2018-09-30\n",
      "amazon:2018-10-01 2018-10-31\n",
      "amazon:2018-11-01 2018-11-30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon:2018-12-01 2018-12-31\n",
      "amazon:2019-01-01 2019-01-31\n",
      "amazon:2019-02-01 2019-02-28\n",
      "amazon:2019-03-01 2019-03-31\n",
      "amazon:2019-04-01 2019-04-30\n",
      "amazon:2019-05-01 2019-05-31\n",
      "amazon:2019-06-01 2019-06-30\n",
      "amazon:2019-07-01 2019-07-31\n",
      "amazon:2019-08-01 2019-08-31\n",
      "amazon:2019-09-01 2019-09-30\n",
      "amazon:2019-10-01 2019-10-31\n",
      "amazon:2019-11-01 2019-11-30\n",
      "amazon:2019-12-01 2019-12-31\n"
     ]
    }
   ],
   "source": [
    "companies_daily_trends(companies, 2015,1, 2019,12)\n",
    "companies_daily_trends(companies, 2020,1, 2020,5)\n",
    "companies_daily_trends_2(companies, 2015,1, 2019,12)\n",
    "companies_daily_trends_2(companies, 2020,1, 2020,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading all the saved csv in the trends file, given a list of keywords and years\n",
    "def reading_trends_df(companies_list, begin_year, end_year):\n",
    "    trends_df = pd.DataFrame()\n",
    "    for company in companies_list:\n",
    "        for year in range(begin_year,end_year+1):\n",
    "            new_company = pd.read_csv(f'../02 CSV_files/trends/daily_trends_{company}{year}.csv', index_col = 0)\n",
    "            trends_df = trends_df.append(new_company)\n",
    "    return trends_df\n",
    "\n",
    "trends_df = reading_trends_df(companies,2015,2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading all the saved csv in the trends file, given a list of keywords and years\n",
    "def reading_trends_df_2(companies_list):\n",
    "    trends_df = pd.DataFrame()\n",
    "    for company in companies_list:\n",
    "        new_company = pd.read_csv(f'../02 CSV_files/trends/daily_trends_{company}.csv', index_col = 0)\n",
    "        trends_df = trends_df.append(new_company)\n",
    "    return trends_df\n",
    "\n",
    "trends_df_2 = reading_trends_df_2(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the trends dataframe before shifting the columns\n",
    "def cleaning_trends_finale(df):\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    df = df.groupby(['date','name']).agg('max').reset_index()\n",
    "    df = df.sort_values(by=['name','date'])\n",
    "    df.drop(columns = 'unscaled', inplace = True)\n",
    "    df.dropna(axis = 0, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_df_2 = cleaning_trends_finale(trends_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating columns referencing previous rows, in order to see the evolution of the trends\n",
    "def shift_n_rows(df,col_name,n_rows):\n",
    "    for col in range(1,n_rows+1):\n",
    "        df[f'{col_name}_day_{col}'] = df[col_name].shift(col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the shift function individualy to each company and combining it afterwards into one dataframe\n",
    "def create_shifted_df(companies_list, df ,col_name, n_of_shifts):\n",
    "    shift = {}\n",
    "    shifted = pd.DataFrame()\n",
    "    for company in companies:\n",
    "        new_df = df[df['name'] == company]\n",
    "        new_df = shift_n_rows(new_df, col_name, n_of_shifts)\n",
    "        shift[company] = new_df\n",
    "        shifted = shifted.append(new_df)\n",
    "    shifted.dropna(axis = 0, inplace = True)\n",
    "    shifted.date = pd.to_datetime(shifted.date)\n",
    "    shifted.to_csv('../02 CSV_files/csv_finals/final_trends.csv')\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trends_shifted = create_shifted_df(companies, trends_df, 'scaled', 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_shifted.to_csv('../02 CSV_files/csv_finals/final_trends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "trends_shifted_2 = create_shifted_df(companies, trends_df_2, 'scaled', 14)\n",
    "trends_shifted_2.to_csv('../02 CSV_files/csv_finals/final_trends_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>scaled</th>\n",
       "      <th>scaled_day_1</th>\n",
       "      <th>scaled_day_2</th>\n",
       "      <th>scaled_day_3</th>\n",
       "      <th>scaled_day_4</th>\n",
       "      <th>scaled_day_5</th>\n",
       "      <th>scaled_day_6</th>\n",
       "      <th>scaled_day_7</th>\n",
       "      <th>scaled_day_8</th>\n",
       "      <th>scaled_day_9</th>\n",
       "      <th>scaled_day_10</th>\n",
       "      <th>scaled_day_11</th>\n",
       "      <th>scaled_day_12</th>\n",
       "      <th>scaled_day_13</th>\n",
       "      <th>scaled_day_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>2015-01-18</td>\n",
       "      <td>netflix</td>\n",
       "      <td>43.07</td>\n",
       "      <td>42.34</td>\n",
       "      <td>30.74</td>\n",
       "      <td>28.42</td>\n",
       "      <td>27.84</td>\n",
       "      <td>26.68</td>\n",
       "      <td>31.32</td>\n",
       "      <td>42.92</td>\n",
       "      <td>46.08</td>\n",
       "      <td>35.20</td>\n",
       "      <td>32.64</td>\n",
       "      <td>34.56</td>\n",
       "      <td>34.56</td>\n",
       "      <td>39.04</td>\n",
       "      <td>55.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>netflix</td>\n",
       "      <td>37.17</td>\n",
       "      <td>43.07</td>\n",
       "      <td>42.34</td>\n",
       "      <td>30.74</td>\n",
       "      <td>28.42</td>\n",
       "      <td>27.84</td>\n",
       "      <td>26.68</td>\n",
       "      <td>31.32</td>\n",
       "      <td>42.92</td>\n",
       "      <td>46.08</td>\n",
       "      <td>35.20</td>\n",
       "      <td>32.64</td>\n",
       "      <td>34.56</td>\n",
       "      <td>34.56</td>\n",
       "      <td>39.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>netflix</td>\n",
       "      <td>29.50</td>\n",
       "      <td>37.17</td>\n",
       "      <td>43.07</td>\n",
       "      <td>42.34</td>\n",
       "      <td>30.74</td>\n",
       "      <td>28.42</td>\n",
       "      <td>27.84</td>\n",
       "      <td>26.68</td>\n",
       "      <td>31.32</td>\n",
       "      <td>42.92</td>\n",
       "      <td>46.08</td>\n",
       "      <td>35.20</td>\n",
       "      <td>32.64</td>\n",
       "      <td>34.56</td>\n",
       "      <td>34.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>netflix</td>\n",
       "      <td>28.32</td>\n",
       "      <td>29.50</td>\n",
       "      <td>37.17</td>\n",
       "      <td>43.07</td>\n",
       "      <td>42.34</td>\n",
       "      <td>30.74</td>\n",
       "      <td>28.42</td>\n",
       "      <td>27.84</td>\n",
       "      <td>26.68</td>\n",
       "      <td>31.32</td>\n",
       "      <td>42.92</td>\n",
       "      <td>46.08</td>\n",
       "      <td>35.20</td>\n",
       "      <td>32.64</td>\n",
       "      <td>34.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>netflix</td>\n",
       "      <td>28.32</td>\n",
       "      <td>28.32</td>\n",
       "      <td>29.50</td>\n",
       "      <td>37.17</td>\n",
       "      <td>43.07</td>\n",
       "      <td>42.34</td>\n",
       "      <td>30.74</td>\n",
       "      <td>28.42</td>\n",
       "      <td>27.84</td>\n",
       "      <td>26.68</td>\n",
       "      <td>31.32</td>\n",
       "      <td>42.92</td>\n",
       "      <td>46.08</td>\n",
       "      <td>35.20</td>\n",
       "      <td>32.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10926</td>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>amazon</td>\n",
       "      <td>55.25</td>\n",
       "      <td>59.50</td>\n",
       "      <td>54.40</td>\n",
       "      <td>46.75</td>\n",
       "      <td>52.70</td>\n",
       "      <td>57.80</td>\n",
       "      <td>69.84</td>\n",
       "      <td>67.90</td>\n",
       "      <td>68.87</td>\n",
       "      <td>71.78</td>\n",
       "      <td>72.75</td>\n",
       "      <td>73.72</td>\n",
       "      <td>75.66</td>\n",
       "      <td>73.92</td>\n",
       "      <td>68.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10932</td>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>amazon</td>\n",
       "      <td>52.70</td>\n",
       "      <td>55.25</td>\n",
       "      <td>59.50</td>\n",
       "      <td>54.40</td>\n",
       "      <td>46.75</td>\n",
       "      <td>52.70</td>\n",
       "      <td>57.80</td>\n",
       "      <td>69.84</td>\n",
       "      <td>67.90</td>\n",
       "      <td>68.87</td>\n",
       "      <td>71.78</td>\n",
       "      <td>72.75</td>\n",
       "      <td>73.72</td>\n",
       "      <td>75.66</td>\n",
       "      <td>73.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10938</td>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>amazon</td>\n",
       "      <td>44.25</td>\n",
       "      <td>52.70</td>\n",
       "      <td>55.25</td>\n",
       "      <td>59.50</td>\n",
       "      <td>54.40</td>\n",
       "      <td>46.75</td>\n",
       "      <td>52.70</td>\n",
       "      <td>57.80</td>\n",
       "      <td>69.84</td>\n",
       "      <td>67.90</td>\n",
       "      <td>68.87</td>\n",
       "      <td>71.78</td>\n",
       "      <td>72.75</td>\n",
       "      <td>73.72</td>\n",
       "      <td>75.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10944</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>amazon</td>\n",
       "      <td>43.50</td>\n",
       "      <td>44.25</td>\n",
       "      <td>52.70</td>\n",
       "      <td>55.25</td>\n",
       "      <td>59.50</td>\n",
       "      <td>54.40</td>\n",
       "      <td>46.75</td>\n",
       "      <td>52.70</td>\n",
       "      <td>57.80</td>\n",
       "      <td>69.84</td>\n",
       "      <td>67.90</td>\n",
       "      <td>68.87</td>\n",
       "      <td>71.78</td>\n",
       "      <td>72.75</td>\n",
       "      <td>73.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10950</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>amazon</td>\n",
       "      <td>40.50</td>\n",
       "      <td>43.50</td>\n",
       "      <td>44.25</td>\n",
       "      <td>52.70</td>\n",
       "      <td>55.25</td>\n",
       "      <td>59.50</td>\n",
       "      <td>54.40</td>\n",
       "      <td>46.75</td>\n",
       "      <td>52.70</td>\n",
       "      <td>57.80</td>\n",
       "      <td>69.84</td>\n",
       "      <td>67.90</td>\n",
       "      <td>68.87</td>\n",
       "      <td>71.78</td>\n",
       "      <td>72.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10854 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     name  scaled  scaled_day_1  scaled_day_2  scaled_day_3  \\\n",
       "103   2015-01-18  netflix   43.07         42.34         30.74         28.42   \n",
       "109   2015-01-19  netflix   37.17         43.07         42.34         30.74   \n",
       "115   2015-01-20  netflix   29.50         37.17         43.07         42.34   \n",
       "121   2015-01-21  netflix   28.32         29.50         37.17         43.07   \n",
       "127   2015-01-22  netflix   28.32         28.32         29.50         37.17   \n",
       "...          ...      ...     ...           ...           ...           ...   \n",
       "10926 2019-12-27   amazon   55.25         59.50         54.40         46.75   \n",
       "10932 2019-12-28   amazon   52.70         55.25         59.50         54.40   \n",
       "10938 2019-12-29   amazon   44.25         52.70         55.25         59.50   \n",
       "10944 2019-12-30   amazon   43.50         44.25         52.70         55.25   \n",
       "10950 2019-12-31   amazon   40.50         43.50         44.25         52.70   \n",
       "\n",
       "       scaled_day_4  scaled_day_5  scaled_day_6  scaled_day_7  scaled_day_8  \\\n",
       "103           27.84         26.68         31.32         42.92         46.08   \n",
       "109           28.42         27.84         26.68         31.32         42.92   \n",
       "115           30.74         28.42         27.84         26.68         31.32   \n",
       "121           42.34         30.74         28.42         27.84         26.68   \n",
       "127           43.07         42.34         30.74         28.42         27.84   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "10926         52.70         57.80         69.84         67.90         68.87   \n",
       "10932         46.75         52.70         57.80         69.84         67.90   \n",
       "10938         54.40         46.75         52.70         57.80         69.84   \n",
       "10944         59.50         54.40         46.75         52.70         57.80   \n",
       "10950         55.25         59.50         54.40         46.75         52.70   \n",
       "\n",
       "       scaled_day_9  scaled_day_10  scaled_day_11  scaled_day_12  \\\n",
       "103           35.20          32.64          34.56          34.56   \n",
       "109           46.08          35.20          32.64          34.56   \n",
       "115           42.92          46.08          35.20          32.64   \n",
       "121           31.32          42.92          46.08          35.20   \n",
       "127           26.68          31.32          42.92          46.08   \n",
       "...             ...            ...            ...            ...   \n",
       "10926         71.78          72.75          73.72          75.66   \n",
       "10932         68.87          71.78          72.75          73.72   \n",
       "10938         67.90          68.87          71.78          72.75   \n",
       "10944         69.84          67.90          68.87          71.78   \n",
       "10950         57.80          69.84          67.90          68.87   \n",
       "\n",
       "       scaled_day_13  scaled_day_14  \n",
       "103            39.04          55.04  \n",
       "109            34.56          39.04  \n",
       "115            34.56          34.56  \n",
       "121            32.64          34.56  \n",
       "127            35.20          32.64  \n",
       "...              ...            ...  \n",
       "10926          73.92          68.16  \n",
       "10932          75.66          73.92  \n",
       "10938          73.72          75.66  \n",
       "10944          72.75          73.72  \n",
       "10950          71.78          72.75  \n",
       "\n",
       "[10854 rows x 17 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trends_shifted_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
